{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e16f892",
   "metadata": {},
   "source": [
    "# Práctica: Precios de Casas en California.\n",
    "\n",
    "El objetivo de esta practica es trabajar con datos antes de inyectarlos a un modelo de aprendizaje automático.\n",
    "Vamos a trabajar con un fichero que contiene un censo de casas del estado de California. Incluye, entre otras, características como la población, los ingresos medios, y el precio mediano de las casas en diferentes \"distritos\" de California.\n",
    "\n",
    "El modelo de aprendizaje automático deberá aprender de los datos de dentrada y ser capaz de predecir el precio mediano en un distrito de California conocidas sus características.\n",
    "\n",
    "Podemos clasificar el problema como aprendizaje supervisado, ya que los datos conocidos incluyen la variable objetivo a predecir. Además es un problema de regresión puesto que el valor que devolverá el modelo puede tomar cualquier valor dentro de un intervalo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5dd479-f31c-435e-ad6c-4d5cc09dd924",
   "metadata": {},
   "source": [
    "## 1. Preparamos el entorno\n",
    "\n",
    "Definimos algunos requisitos para las librerías usadas y las versiones de Python para no tener problemas de compatibilidad con las funciones que vamos a usar.\n",
    "Generamos un directorio donde guardar las imágenes que iremos generando durante el `Notebook`. Este directorio estará un nivel por encima del fichero `.ipynb` y alojará las imágenescon extensión `.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "582dfcd6-ecd4-4d29-b29c-33c47ea579e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "#PROJECT_ROOT_DIR = os.getcwd()\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.abspath(os.path.join(PROJECT_ROOT_DIR, \"Imagenes\"))\n",
    "#IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"Imagenes\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300, images_path = IMAGES_PATH):\n",
    "    if not os.path.isdir(images_path):\n",
    "        os.makedirs(images_path)\n",
    "    path = os.path.join(images_path, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aa48dc-2e0c-49b9-afb5-8a5852548b49",
   "metadata": {},
   "source": [
    "## 2. Obtener los datos de entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08d8a55-d219-4863-81df-d11cc8ab4a26",
   "metadata": {},
   "source": [
    "### 2.1. Descarga de datos\n",
    "\n",
    "Vamos a descargar el fichero `housing.tgz` del repositorio de [Aurélien Géron](https://github.com/ageron/handson-ml3) y usaremos una función para descomprimirlo y almacenarlo con extensión `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcabc278-3d7d-430e-9a5f-e7b19d5adf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(PROJECT_ROOT_DIR,\"Archivos\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5191bf",
   "metadata": {},
   "source": [
    " LLamamos a la función que creará una nueva carpeta `\\Archivos\\housing\\` a la misma altura que `\\Imagenes\\` dentro del árbol de directorios, donde almacenará `housing.tgz` y su equivalente `housing.csv` descomprimido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f88b59-456f-47cf-a66e-cac85fb68b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/t4m6mlzx36x9ywgp0g288tsh0000gn/T/ipykernel_19180/2869986572.py:15: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  housing_tgz.extractall(path=housing_path)\n"
     ]
    }
   ],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144488ac",
   "metadata": {},
   "source": [
    "Cargamos el fichero en un *DataFrame* de *`Pandas`*  de nombre *housing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "212f73db-cef2-4d9b-b9a7-41286e998c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b333bd-5a0d-416a-86ba-8a03d3d1761b",
   "metadata": {},
   "source": [
    "### 2.2. Primer vistazo a la estructura de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a593faf-3338-4019-9901-ad0ab2de5a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41ab099d-1e4b-4818-b8fc-5c601feb4394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1982d3-3277-4e1f-b897-123c69251bed",
   "metadata": {},
   "source": [
    "En esta primera exploración vemos que hay 20640 registros de distritos en California. Sin embargo la columna de *total_bedrooms* solo tiene 20433 valores lo que implica que faltan 207 distritos con esa información.\n",
    "Todos las \"features\" son numéricas salvo *ocean_proximity* que es de tipo \"object\", lo que significa que puede ser cualquier cosa. Exploremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0272aea1-3c42-4665-9170-7d4c65b646e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ocean_proximity\n",
       "<1H OCEAN     9136\n",
       "INLAND        6551\n",
       "NEAR OCEAN    2658\n",
       "NEAR BAY      2290\n",
       "ISLAND           5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing[\"ocean_proximity\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becc729c-fb20-48b2-93f7-a4cb4e18952e",
   "metadata": {},
   "source": [
    "La variable *ocean_proximity* puede tomar 5 valores categóricos diferentes que parecen indicar la localización del distrito dentro del estado de California respecto a su distancia al océano. Luego veremos como trabajamos con ellos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa7512",
   "metadata": {},
   "source": [
    "Veamos ahora que información tenemos en las variables numéricas. Usaremos \n",
    "```python  \n",
    ".describe()\n",
    "```\n",
    "que nos muestra un resumen de caracter estadístico de cada variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd88628-e1bb-4db4-bf6e-c3ed14d71f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223b537-7dbe-46d5-87b4-f8286b3b5a9e",
   "metadata": {},
   "source": [
    "### 2.2.1. Histograma con las variables numéricas.\n",
    "\n",
    "La información que proporciona *`.describe()`* es bastante descriptiva pero la vamos a reforzar dibujando el histograma con la frecuencia de cada característica.\n",
    "Usaremos el metodo *`.hist`*  sobre el DataFrame completo *housing* para representar un histograma para cada variable numérica.\n",
    "Guardaremos además la figura en la carpeta `\\Imagenes\\`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0bc378-808a-4db2-ab2e-5d05ccb30065",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "%matplotlib inline \n",
    "# Para adaptarlo al formato del Notebook\n",
    "import matplotlib.pyplot as plt\n",
    "housing.hist(bins=50, figsize=(20,15))\n",
    "save_fig(\"attribute_histogram_plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194c8f8f-6536-4348-8ace-47ee33ca68c0",
   "metadata": {},
   "source": [
    "Cosas en las que fijarse.\n",
    "* La categoría *median_income* está escalada de modo que el valor expresado es en decenas de miles de dolares. Así 5 quiere decir 50.000 dólares\n",
    "* Las categorías *housing_median_age* y *median_house_value* están truncadas de manera que toda antiguedad superior a 50 se ha incluido en el grupo de 50 años. Lo mismo ocurre con el valor a predecir, el precio mediano en el distrito, que, por encima de 500.000 dolares, está \"colapsado\" lo que puede ser un problema a la hora de predecir correctamente los precios. Ya veremos como trabajamos con estos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6c573",
   "metadata": {},
   "source": [
    "### 2.3 Representación 'geográfica' de los datos.\n",
    "\n",
    "Aprovechando que tenemos información de la latitud y longitud de los distritos para los que queremos predecir el precio mediano de las viviendas, vamos a representarlos en un mapa.\n",
    "\n",
    "En una primera versión de la gráfica simplemente representamos en un `scatterplot`, añadiendo el parámetro *alpha = 0.1* que determina la transparencia de los datos. Así si hay zonas con varios puntos aparecerán más marcadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Crear el gráfico de dispersión con seaborn\n",
    "plt.figure(figsize=(10, 6))  # Ajustar el tamaño de la figura (opcional)\n",
    "sns.scatterplot(data=housing, x=\"longitude\", y=\"latitude\", alpha=0.1)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n",
    "save_fig(\"mapa_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50179c1a",
   "metadata": {},
   "source": [
    "Vamos a mejorar el gráfico. Ahora incluímos:\n",
    "*  el tamaño de los puntos `s` dependiente de la población total del distrito. \n",
    "*  el color `c` basado en la variable a predecir *median_house_value*\n",
    "*  la transparencia `alpha`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d722730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del gráfico\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Crear el gráfico de dispersión con Seaborn\n",
    "scatter = plt.scatter(\n",
    "    housing[\"longitude\"], \n",
    "    housing[\"latitude\"], \n",
    "    s=housing[\"population\"]/100,           # Tamaño de los puntos\n",
    "    c=housing[\"median_house_value\"],       # Colorear según median_house_value\n",
    "    cmap=\"jet\",                            # Colormap jet\n",
    "    alpha=0.4,                             # Transparencia\n",
    ")\n",
    "\n",
    "# Añadir la barra de colores\n",
    "plt.colorbar(label=\"Median House Value\")\n",
    "\n",
    "# Añadir etiquetas y leyenda\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.legend([\"Population\"], loc=\"upper right\")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n",
    "save_fig(\"mapa_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a4409e",
   "metadata": {},
   "source": [
    "Por último vamos a ir bastante más allá descargando un mapa de California y usandolo como fondo sobre el que representar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d364f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the California image\n",
    "images_path = os.path.join(PROJECT_ROOT_DIR, \"Imagenes\")\n",
    "os.makedirs(images_path, exist_ok=True)\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "filename = \"california.png\"\n",
    "print(\"Downloading\", filename)\n",
    "url = DOWNLOAD_ROOT + \"images/end_to_end_project/\" + filename\n",
    "urllib.request.urlretrieve(url, os.path.join(images_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07762e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Cargar la imagen de fondo (mapa de California)\n",
    "california_img = mpimg.imread(os.path.join(IMAGES_PATH, filename))\n",
    "\n",
    "# Configurar el tamaño del gráfico\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Dibujar el scatter plot sobre el mapa de California\n",
    "scatter = plt.scatter(\n",
    "    housing[\"longitude\"], \n",
    "    housing[\"latitude\"], \n",
    "    s=housing['population']/100,           # Tamaño de los puntos según la población\n",
    "    c=housing[\"median_house_value\"],       # Colorear según median_house_value\n",
    "    cmap=\"jet\",                            # Colormap \"jet\"\n",
    "    alpha=0.4                              # Transparencia\n",
    ")\n",
    "\n",
    "# Mostrar la imagen de fondo\n",
    "plt.imshow(\n",
    "    california_img, \n",
    "    extent=[-124.55, -113.80, 32.45, 42.05],  # Extensión geográfica del mapa\n",
    "    alpha=0.5,                                 # Transparencia de la imagen\n",
    "    cmap=plt.get_cmap(\"jet\")\n",
    ")\n",
    "\n",
    "# Etiquetas de los ejes\n",
    "plt.ylabel(\"Latitude\", fontsize=14)\n",
    "plt.xlabel(\"Longitude\", fontsize=14)\n",
    "\n",
    "# Crear la barra de colores personalizada\n",
    "prices = housing[\"median_house_value\"]\n",
    "tick_values = np.linspace(prices.min(), prices.max(), 11)  # Definir los valores de los ticks\n",
    "cbar = plt.colorbar(scatter)  # Añadir la barra de colores\n",
    "cbar.set_ticks(tick_values)   # Establecer los valores de los ticks\n",
    "cbar.set_ticklabels([f\"${int(v/1000)}k\" for v in tick_values])  # Formato en miles de dólares\n",
    "cbar.ax.tick_params(labelsize=14)  # Tamaño de las etiquetas de la barra\n",
    "cbar.set_label('Median House Value', fontsize=16)\n",
    "\n",
    "# Añadir leyenda\n",
    "plt.legend([\"Population\"], fontsize=16)\n",
    "\n",
    "# Guardar la figura en el directorio 'Imagenes'\n",
    "save_fig(\"mapa_3\")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66c42c8-153f-4b38-9b45-af3e4a05aff2",
   "metadata": {},
   "source": [
    "## 3. Análisis Exploratorio de Datos (EDA).\n",
    "\n",
    "En esta sección vamos a incluir una serie de actuaciones para preparar los datos de cara al modelo de aprendizaje automático. \n",
    "Entre otras:\n",
    "\n",
    "* Buscaremos como correlacionan las variables numericas entre sí. En particular veremos cuales están más relacionadas con la variable que queremos predecir.\n",
    "* Eliminaremos del análisis aquellas columnas que no aportan información.\n",
    "* Crearemos características nuevas basadas en las existentes si consideramos que pueden ser útiles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c174b960-6273-411e-bc9f-ab69c624fba6",
   "metadata": {},
   "source": [
    "### 3.1. Correlación.\n",
    "\n",
    "Para mostrar la matriz de correlación entre las variables numéricas, necesitas eliminar o ignorar las columnas categóricas como *ocean_proximity*, ya que las correlaciones se calculan entre variables numéricas. Las variables categóricas no pueden participar en el cálculo de la correlación de Pearson (que es el tipo más común), ya que esta mide la relación lineal entre números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna categórica para calcular la correlación\n",
    "housing_numeric = housing.drop(\"ocean_proximity\", axis=1)\n",
    "\n",
    "# Calcular la matriz de correlación\n",
    "corr_matrix = housing_numeric.corr()\n",
    "\n",
    "# Mostrar la matriz de correlación\n",
    "corr_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bda904",
   "metadata": {},
   "source": [
    "De forma mas visual representamos la matriz de correlación en un heatmap utilizando Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b73dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el tamaño de la figura\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Crear el heatmap\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", linewidths=0.5)\n",
    "\n",
    "# Añadir título\n",
    "plt.title(\"Matriz de correlación\", fontsize=16)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n",
    "\n",
    "# Guardar la figura en el directorio 'Imagenes'\n",
    "save_fig(\"correlacion_total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d31f023-11f2-44b7-bd76-a879500ba553",
   "metadata": {},
   "source": [
    "Como la variable que queremos predecir es *median_house_value* vamos a fijarnos como se relaciona cada \"característica\" con ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f48b173-cd99-4644-a466-f476cf6cb4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7abc700",
   "metadata": {},
   "source": [
    "Aparte del 1 de *median_house_value* consigo misma, la característica que parece ser más explicativa del precio mediano por distrito es el salario mediano en el distrito.\n",
    "Vamos a hacer un `scatterplot` de una frente a otra para explorar mejor la relación existente.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d62638-7f02-4777-b201-0c641f6acc4d",
   "metadata": {},
   "source": [
    "Fijemonos en la variable más \"prometedora\" la median_income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97970f0-37ce-4d4f-8b79-5dd2d2eb8788",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
    "             alpha=0.1)\n",
    "plt.axis([0, 16, 0, 550000])\n",
    "save_fig(\"income_vs_house_value_scatterplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e581614c-57d8-4178-9a98-2e56f58c763e",
   "metadata": {},
   "source": [
    "Hay una tendencia muy visible por la que el precio mediano de las casas de un barrio crece con el nivel de ingresos de los habitantes del mismo, pero tambien detectamos valores anómalos. Se ve el tope ya comentado en 500.000 dólares, pero también otras tendencias extrañas en 450.000 y 350.000. Quiza queramos eliminar esos distritos anómalos para evitar que nuestro modelo reproduzca información manipulada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcfddf6-0bb9-4d0c-922d-93b3b5aa8278",
   "metadata": {},
   "source": [
    "### 3.2. Nuevas características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d60fbe-84bc-4fad-ba88-600d77a33261",
   "metadata": {},
   "source": [
    "Entre el conjunto de \"features\" hay algunas que no tienen sentido por si solas ¿Qué información da el número total de habitaciones en un distrito o el número total de dormitorios? Hemos visto además que su correlación con la variable a predecir es baja. ¿No tiene más sentido expresar esas variables en relación al número de viviendas? Lo mismo ocurre con la población de cada distrito, quizá es más útil saber el número medio de convivientes por casa.\n",
    "\n",
    "Vamos a añadir 3 columnas a nuestro *DataFrame*:\n",
    "\n",
    "* *rooms_per_household*: Número medio de estancias por vivienda.\n",
    "* *bedrooms_per_rooms*: Ratio de dormitorios frente a número de estancias en una vivienda.\n",
    "* *population_per_household*: Número medio de convivientes por vivienda.\n",
    "\n",
    "Estas características quizá expliquen mejor el precio mediano de la vivienda en un distrito ya que quiza pueden reflejar mejor si nos encontramos en un barrio densamente poblado, si predominan viviendas unifamiliares o si en las viviendas de un distrito predominan los dormitorios (¿alquileres por habitación?) frente a los espacios comunes.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401fb89-e98c-48ef-a5cc-e1e249961b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_rooms\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a63bd-bfd0-48f4-9e28-6de58c53acec",
   "metadata": {},
   "source": [
    "Veamos si nuestras nuevas variables correlacionan mejor con el *median_house_value*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa35c7-f80e-472b-8ade-6f5360b0423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna categórica para calcular la correlación\n",
    "housing_numeric = housing.drop(\"ocean_proximity\", axis=1)\n",
    "\n",
    "# Calcular la matriz de correlación\n",
    "corr_matrix = housing_numeric.corr()\n",
    "\n",
    "# Obtener los coeficientes de correlación con 'median_house_value'\n",
    "corr_with_median_house_value = corr_matrix[\"median_house_value\"]\n",
    "\n",
    "# Ordenar por valor absoluto\n",
    "sorted_corr = corr_with_median_house_value.abs().sort_values(ascending=False)\n",
    "sorted_corr = corr_with_median_house_value.loc[sorted_corr.index]\n",
    "\n",
    "# Asignar colores basados en el signo del coeficiente\n",
    "colors = ['red' if val < 0 else 'blue' for val in sorted_corr]\n",
    "\n",
    "# Crear el gráfico de barras sin pintar la correlación consigo misma\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(sorted_corr.index[1:], sorted_corr.values[1:], color=colors[1:])\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.ylabel(\"Coeficiente de Correlación\")\n",
    "plt.title(\"Coeficientes de Correlación con Median House Value (Ordenados por Valor Absoluto)\")\n",
    "\n",
    "# Rotar las etiquetas del eje x para mejor legibilidad\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n",
    "save_fig(\"new_corr_median_house_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33539721",
   "metadata": {},
   "source": [
    "Los resultados parecen tener sentido. Cuanto mayor es el ratio $ \\frac{dormitorios}{estancias}$ indica que la vivienda dispone de menos espacios comunes. Eso es más habitual en viviendas que se destinan a alquiler por habitaciones y menos en viviendas unifamiliares. Quizá eso explica la relación negativa entre el precio mediano y el ratio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28157765",
   "metadata": {},
   "source": [
    "Nuestro *DataFrame* ahora ha cambiado. Veamos la información que ahora contiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5d4f7-27c2-49c2-8f49-b207238c07ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0aad61-d79d-4b57-8d9b-6dd46535c63a",
   "metadata": {},
   "source": [
    "## 4. Preparando los datos para los algoritmos de aprendizaje automático."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3669559-0ce4-451f-9924-60907a2e926f",
   "metadata": {},
   "source": [
    "### 4.1. Datos Faltantes.\n",
    "\n",
    "Al principio vimos que no teniamos los valores para *total_bedroom* de todos los barrios. Hay varias posibilidades:\n",
    "\n",
    "* Eliminar todos los registros donde no tenemos información de esa variable de entrada.\n",
    "* Eliminar dicha columna ya que hemos visto que no está muy correlacionada con la variable a predecir.\n",
    "* Imponiendo un valor ficticio que no distorsione mucho los datos, como puede ser la media o la mediana.\n",
    "\n",
    "(¿Cuál usarías?)\n",
    "\n",
    "Para ver como hacer cada una de las posibilidades vamos a copiar en un *DataFrame* los registros que no tiene ese dato.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = housing['total_bedrooms'].isnull()\n",
    "idx.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05088812-64e3-41a3-b898-f782dc19284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_incomplete_rows = housing[idx].head()\n",
    "sample_incomplete_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f60a4cc-3ed5-4991-8ac8-1bcd68d6d521",
   "metadata": {},
   "source": [
    "La opción 1 es eliminar dichos registros.\n",
    "En el código si quisieras usar esta opción sobre el *DataFrame* real pondríamos:\n",
    "```python\n",
    "housing_clean_1 = housing.dropna(subset=['total_bedrooms'])\n",
    "```\n",
    "o \n",
    "```python\n",
    "idx = housing['total_bedrooms'].isnull()\n",
    "housing_clean_1 = housing[~idx] \n",
    "```\n",
    "o \n",
    "```python\n",
    "idx = housing['total_bedrooms'].notnull()\n",
    "housing_clean_1 = housing[idx] \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57829160-8d8b-4036-b830-75a65ad46a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = housing['total_bedrooms'].notnull()\n",
    "housing_clean_1 = housing[idx]\n",
    "housing_clean_1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b510db7e-2ec0-4c1e-a840-59e7a38427a5",
   "metadata": {},
   "source": [
    "La opción 2 es eliminar dicha característica de todos los registros.\n",
    "En el código si quisieras usar esta opción sobre el *DataFrame* real pondríamos:\n",
    "```python\n",
    "housing_clean_2 = housing.drop(\"total_bedrooms\", axis=1) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a98bd-4e9e-4c46-84bc-93eded2fa82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_clean_2 = housing.drop(\"total_bedrooms\", axis=1)\n",
    "housing_clean_2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2cf317-9349-4e8e-b91f-470d0f5b5c13",
   "metadata": {},
   "source": [
    "Por último la opción 3 es rellenar en todos los registros donde falte esa información el valor mediano (El valor medio se podría ver afectado por valores anómalos incorrectos).\n",
    "```python \n",
    "# Calcular la mediana de 'total_bedrooms'\n",
    "median_total_bedrooms = housing['total_bedrooms'].median()\n",
    "\n",
    "# Crear un nuevo DataFrame y rellenar los valores nulos en 'total_bedrooms' con la mediana\n",
    "housing_clean_3 = housing.copy()\n",
    "housing_clean_3['total_bedrooms'] = housing['total_bedrooms'].fillna(median_total_bedrooms)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e850a70d-b54e-47a1-ad88-4bb307dee5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la mediana de 'total_bedrooms'\n",
    "median_total_bedrooms = housing['total_bedrooms'].median()\n",
    "\n",
    "# Crear un nuevo DataFrame y rellenar los valores nulos en 'total_bedrooms' con la mediana\n",
    "housing_clean_3 = housing.copy()\n",
    "housing_clean_3['total_bedrooms'] = housing['total_bedrooms'].fillna(median_total_bedrooms)\n",
    "\n",
    "housing_clean_3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588d1ee0-fd38-4e51-8685-4547184078aa",
   "metadata": {},
   "source": [
    "Vamos a escoger esta última opción.\n",
    "Debemos fijarnos que la caracteristica creada *bedrooms_per_room* depende del valor de *total_bedrooms*. Así que también tiene valores nulos que debemos rellenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39f805a-bf52-48c8-b652-0d629426e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la mediana de 'total_bedrooms'\n",
    "median_total_bedrooms = housing['total_bedrooms'].median()\n",
    "median_bedrooms_per_room = housing['bedrooms_per_rooms'].median()\n",
    "\n",
    "# Crear un nuevo DataFrame y rellenar los valores nulos en 'total_bedrooms' y 'bedrooms_per_room' con la mediana\n",
    "housing_clean = housing.copy()\n",
    "housing_clean['total_bedrooms'] = housing['total_bedrooms'].fillna(median_total_bedrooms)\n",
    "housing_clean['bedrooms_per_rooms'] = housing['bedrooms_per_rooms'].fillna(median_bedrooms_per_room)\n",
    "\n",
    "housing_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef291a51-3e98-457a-83f7-2d7ca082c1dd",
   "metadata": {},
   "source": [
    "### 4.2. Estandarizar/Escalar los datos de entrada. \n",
    "\n",
    "En el preprocesamiento de datos para el aprendizaje automático es importante que todas las características están en escalas parecidas para evitar que su importancia en el modelo se sobre o infravalore. Hay diferentes maneras de hacerlo, aquí vamos a usar Z-Score Standard Scaler que ajusta la característica restando su media y dividiendo por la desviación estándar.\n",
    "\n",
    "De un modo práctico voy a definir una función que reciba un *DataFrame* y el conjunto de columnas que **no** quiero estandarizar. Este argumento lo voy a usar porque la variable a predecir *median_house_value* no la vamos a escalar ya que nos puede dificultar interpretar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26907483-6222-4280-b009-d28cb5320fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize_dataframe(df, column_names):\n",
    "    # Select numerical columns\n",
    "    numerical_cols = df.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Exclude the columns specified in column_names\n",
    "    numerical_cols_to_standardize = numerical_cols.drop(columns=column_names)\n",
    "\n",
    "    # Standardize numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    scaled_numerical_cols = scaler.fit_transform(numerical_cols_to_standardize)\n",
    "    df[numerical_cols_to_standardize.columns] = scaled_numerical_cols\n",
    "\n",
    "    return df\n",
    "housing_stand = standardize_dataframe(housing_clean.copy(),[\"median_house_value\"])\n",
    "housing_stand.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149c3601",
   "metadata": {},
   "source": [
    "Fijate en los valores de la media para todas las variables numéricas son 0 (e-15 es computacionalmente 0) salvo para la variable a predecir.\n",
    "\n",
    "Ahora *`housing_stand`* es el *DataFrame* con las variables de entrada escaladas y sin datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d4417-9f55-4b47-9c63-bcd02c11cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_stand.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626446d2-1b31-4330-883e-c3f3e3b6a877",
   "metadata": {},
   "source": [
    "### 4.3. Manejando variables categóricas.\n",
    "\n",
    "Vamos a preprocesar la variable categórica *ocean_proximity*. Para jugar con ella voy a crear un *DataFrame* que contenga solamente 3 columnas: 2 numéricas: *median_income* y la variable a predecir *median_house_value* y, por otro lado, la variable categórica *ocean_proximity*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389bf6c-2553-43b5-a559-654ac4029ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat = housing[[\"median_income\",\"median_house_value\",\"ocean_proximity\"]]\n",
    "housing_cat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1364e605-9ce5-40c5-b2ac-f4afaae741ca",
   "metadata": {},
   "source": [
    "#### Label Encoding.\n",
    "Una posibilidad de codificar los valores de texto de forma numérica es simplemente asignarle a cada uno de ellos un número. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d195ec-4775-4f79-951c-9da73b959850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder  # Import LabelEncoder\n",
    "\n",
    "# Create a label encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Encode the categorical variable\n",
    "housing_cat_encoded = encoder.fit_transform(housing_cat[\"ocean_proximity\"])\n",
    "\n",
    "# Combine the encoded column with the original DataFrame (excluding ocean_proximity)\n",
    "housing_cat_encoded = pd.DataFrame({'ocean_proximity': housing_cat_encoded})\n",
    "housing_cat_full = pd.concat([housing_cat[[\"median_income\", \"median_house_value\"]], housing_cat_encoded], axis=1)\n",
    "\n",
    "# Print the full DataFrame\n",
    "print(housing_cat_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f4d01a-6624-43b7-8f96-fa754f1a2693",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0158d67b-ec7f-442d-9555-db167c397da6",
   "metadata": {},
   "source": [
    "Hemos convertido la variable categórica en una numérica. El problema es que al trabajar con números damos por hecho que el '0' está más cerca del '1' que del '4'. En este caso '0' correspode a las viviendas que cumplen *<1H OCEAN* que suponemos que deberían estar más cerca de las viviendas codificadas como '4' *NEAR OCEAN* que de aquellas codificadas con '1' *INLAND*.\n",
    "\n",
    "#### One-Hot Encoding \n",
    "Para evitar que el modelo asuma que existe un orden en la variable *ocean_proximity* usamos un codificador que no genere un orden artificial en variables categóricas, el `One-Hot Encoding`.\n",
    "\n",
    "De nuevo, de modo práctico voy a definir una función que reciba un *DataFrame* y el conjunto de columnas categóricas que quiero codificar. Devolverá el *DataFrame* con las columnas codificadas usando la estrategia `One-Hot Encoding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb4925-df00-42cb-b8ae-30f965083108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def onehot_dataframe(df, column_names):\n",
    "    categorical_cols = df[column_names]\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(categorical_cols)\n",
    "    encoded_data = encoder.transform(categorical_cols)\n",
    "    encoded_df = pd.DataFrame(encoded_data.toarray(), columns=encoder.get_feature_names_out(column_names))\n",
    "    df = df.drop(columns=column_names)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df_encoded = pd.concat([df, encoded_df], axis=1)\n",
    "    return df_encoded\n",
    "\n",
    "housing_encoded = onehot_dataframe(housing_cat.copy(),[\"ocean_proximity\"])\n",
    "housing_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c6dbe-0fd2-449c-b53c-564b01e067da",
   "metadata": {},
   "source": [
    "Ahora que lo hemos probado en un mini *DataFrame* vamos a emplear esa estrategia para codificar la variable categorica del conjunto de datos previamente estandarizado *`housing_stand`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379b4b52-88d0-4048-aca6-8d852d900f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_stand_1hotcoded = onehot_dataframe(housing_stand.copy(),[\"ocean_proximity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b53b64-f3ea-422f-a32a-311266a4ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_stand_1hotcoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011eed48-403a-4277-b9e7-328e62f80bd6",
   "metadata": {},
   "source": [
    "## 5. División del conjunto de datos en Training y Test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd57e5b-0759-4548-a169-d4e9f3941152",
   "metadata": {},
   "source": [
    "El *Train-Test Split* es una técnica que consiste en dividir el conjunto de datos disponibles en dos subconjuntos: uno para el entrenamiento del modelo (Train Set) y otro para la evaluación del mismo (Test Set). \n",
    "Lo primero que voy a hacer por simplicidad es renombrar la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb27a97-2988-46ab-96e1-1894890656c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared = housing_stand_1hotcoded.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c3d155",
   "metadata": {},
   "source": [
    "Vamos a seguir dos estrategias:\n",
    "\n",
    "* La más sencilla: dividimos el conjunto usando la partición habitual 80-20%\n",
    "\n",
    "* **Opcional** Vamos a hacer la división garantizando que los datos en los conjuntos de Test y Training se distribuyen en la misma proporción que en la variable más representativa *median_house_value* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e51906",
   "metadata": {},
   "source": [
    "### Holdout 80-20% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec6dc30-2f30-4499-919f-cd037f5ef33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(housing_prepared, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105906b-2415-414d-99d9-fb07f53bfec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d6ddc9",
   "metadata": {},
   "source": [
    "### Opcional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0a9641-817d-45fe-911f-d30d07ce4f0e",
   "metadata": {},
   "source": [
    "¿Cómo podemos asegurarnos de que nuestra división *train/test* es representativa respecto al conjunto original? \n",
    "Por ejemplo, con todo lo que hemos visto hasta ahora sabemos que la variable que más correlaciona con la variable a predecir es *median_income*. Nos gustaría que los datos en *train* se distribuyeran de la misma manera que el conjunto original respecto a sus valores de *median_income*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa14c44-9b56-4cc8-b975-7c5d616bcabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared[\"median_income\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac9a89-ff48-4237-bb72-d39173b9c9ba",
   "metadata": {},
   "source": [
    "En valores estandarizados vemos que la distribución esta sesgada a la izquierda. Creamos una nueva variable de entrada donde agrupamos con etiquetas los grupos mas representativos de la variable *median_income*. Los grupos serán: [-2.,-1.], [-1., 0.], [0.,1.], [1.,2.], [2.,$\\infty$] etiquetadas del 1 al 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7849598-7c40-48b3-a462-0cb8ab56be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared[\"income_cat\"] = pd.cut(housing_prepared[\"median_income\"],\n",
    "                               bins=[-2., -1., 0., 1., 2., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d414849-f2eb-497e-8403-854380ff8ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared[\"income_cat\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97fcb7a-49a5-47a6-8789-0e423bee1144",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared[\"income_cat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335e827-729d-4e75-b8c4-1e5fd39c17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared[\"income_cat\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31634de8-9448-4cec-9ab5-a98618e0a58d",
   "metadata": {},
   "source": [
    "Sabiendo que el conjunto de datos de entrada se reparten de esta manera respecto a la variable *median_income* lo que queremos es que los datos de entrenamiento *train* mantengan esta proporción. Sería algo asi como en cada grupo de income_cat hacer un train/test al 80%-20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31942dd-f39a-4a55-a1bc-ce33167501bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing_prepared, housing_prepared[\"income_cat\"]):\n",
    "    strat_train_set = housing_prepared.loc[train_index]\n",
    "    strat_test_set = housing_prepared.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0aa2b9-2c89-4c6e-bccc-80e63c75f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc7bef4-462f-44cd-8648-051ac1da6e67",
   "metadata": {},
   "source": [
    "Este es el porcentaje de registros del nuevo *train* en cada una de los subconjuntos de *median_income*.\n",
    "Calculemos lo mismo para los datos originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78177a13-bad4-4514-99be-3a24dceed7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared[\"income_cat\"].value_counts() / len(housing_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b6e73b-7880-4718-9be0-49fcf4f3f783",
   "metadata": {},
   "source": [
    "Perfecto!\n",
    "\n",
    "Veamos si nuestra división original en entrenamiento y test respetaba esa proporción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67407fdf-b9ff-4642-81d2-e113de9181a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def income_cat_proportions(data):\n",
    "    return data[\"income_cat\"].value_counts() / len(data)\n",
    "\n",
    "train_set, test_set = train_test_split(housing_prepared, test_size=0.2, random_state=42)\n",
    "\n",
    "compare_props = pd.DataFrame({\n",
    "    \"Overall\": income_cat_proportions(housing_prepared),\n",
    "    \"Stratified\": income_cat_proportions(strat_test_set),\n",
    "    \"Random\": income_cat_proportions(test_set),\n",
    "}).sort_index()\n",
    "compare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\n",
    "compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100\n",
    "compare_props"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07c936-0623-4025-8f8c-e8c060722128",
   "metadata": {},
   "source": [
    "Como vemos no es tan preciso. Así que a partir de ahora usaremos la división *train/test* respetuoso con los porcentajes de la categoría *median_income*.\n",
    "Eliminamos del nuevo *train/test* la categoria artificial que creamos antes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a5055-121b-46c2-8bd5-4e6247aeb7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ae91e-b8b7-4d45-8d8e-0d87d6ab7fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b1ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = strat_train_set\n",
    "test_set  = strat_test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44cb97",
   "metadata": {},
   "source": [
    "### Fin de la parte opcional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488504f2-995b-4693-b4a4-7028274febfd",
   "metadata": {},
   "source": [
    "## 6. Regresión Lineal usando SKLearn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a039e30-f929-4774-b81e-008aa60a62fb",
   "metadata": {},
   "source": [
    "Lo primero que haremos será dividir los datos en variables de entrada y la salida que queremos predecir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3eeea7-b2eb-4223-ac56-22ac72d1abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_input = train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
    "housing_labels = train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf425c5-d921-41ce-80d8-b1c14817117f",
   "metadata": {},
   "source": [
    "### 6.1. Entrenamiento y evaluación en el conjunto de datos de entrenamiento.\n",
    "\n",
    "Generamos el modelo de regresión lineal y lo entrenamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e04f55-8c31-4df5-9187-d30bbd8b0fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_input, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfaa7aa-8744-42e2-ad1f-615e0076a8cd",
   "metadata": {},
   "source": [
    "Veamos como funciona en datos de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3554b41-baa0-458a-b70f-590f92c177ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = housing_input.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "\n",
    "print(\"Predictions:\", lin_reg.predict(some_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2448068-acc9-4078-a816-ede1d0006800",
   "metadata": {},
   "source": [
    "Comparamos con los precios reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ae803-45b1-40bc-bd3e-3045389ca623",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c823c5-5fb2-43b4-b6e9-f2720c9fb1fe",
   "metadata": {},
   "source": [
    "Obtengamos métricas del error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ba9b2-8d78-4d50-8961-218d4be18d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "housing_predictions = lin_reg.predict(housing_input)\n",
    "\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c48c591-5484-4b76-a683-91f18cae1ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lin_mae = mean_absolute_error(housing_labels, housing_predictions)\n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b9a77c",
   "metadata": {},
   "source": [
    "¿Que significan esos valores? \n",
    "Vamos a usar un gráfico de dispersión para ver mejor como se comporta el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7577ba3-3345-4ef4-8082-cdf2409eee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear el gráfico de dispersión\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(housing_labels, housing_predictions, alpha=0.5)\n",
    "\n",
    "# Añadir línea de referencia y etiquetas\n",
    "plt.plot([housing_labels.min(), housing_labels.max()], [housing_labels.min(), housing_labels.max()], \"r--\", lw=2)  # Línea de referencia y=y\n",
    "plt.xlabel(\"Valores Reales (Median House Value)\")\n",
    "plt.ylabel(\"Predicciones\")\n",
    "plt.title(\"Predicciones vs Valores Reales\")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb429ad8",
   "metadata": {},
   "source": [
    "Los resultados pueden ser bastante decepcionantes. El error cometido por el modelo es muy grande. Pero ten en cuenta que no hemos \"limpiado\" completamente los datos. Por ejemplo no hemos considerado que los datos están colapsados por encima de 500000$. Además la regresión lineal puede no ser el mejor modelo para trabajar con este conjunto de datos. La hemos empleado por simplicidad.\n",
    "\n",
    "Prueba a repetir los cálculo pero eliminando de los datos originales los distritos donde la variable `median_house_value` toma valor $ \\geq 500000$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
